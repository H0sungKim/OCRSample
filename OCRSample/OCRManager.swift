//
//  OCRManager.swift
//  OCRSample
//
//  Created by ê¹€í˜¸ì„± on 2024.11.15.
//

import Foundation
import VisionKit
import Vision
import CoreML

class OCRManager {
    
    public static let shared = OCRManager()
    
    private init() {
        
    }
    
    func extractText(from image: UIImage, completion: @escaping (String?) -> Void) {
        guard let cgImage: CGImage = image.cgImage else { return completion(nil) }
        let requestHandler = VNImageRequestHandler(cgImage: cgImage)
        let request = VNRecognizeTextRequest { request, error in
            guard let observations = request.results as? [VNRecognizedTextObservation] else { return completion(nil) }
            var recognizedStrings = observations.compactMap { observation in
                // Return the string of the top VNRecognizedText instance.
                print(observation)
                print(observation.topCandidates(1).first?.confidence)
                if observation.topCandidates(1).first?.string != "ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã£ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚’ã‚“" && observation.topCandidates(1).first?.string != "ã‚¢ã‚¤ã‚¦ã‚¨ã‚ªã‚«ã‚­ã‚¯ã‚±ã‚³ã‚µã‚·ã‚¹ã‚»ã‚½ã‚¿ãƒãƒ„ãƒ†ãƒˆãƒŠãƒ‹ãƒŒãƒãƒãƒãƒ’ãƒ•ã¸ãƒ›ãƒãƒŸãƒ ãƒ¡ãƒ¢ãƒ¤ãƒ¦ãƒ¨ãƒ©ãƒªãƒ«ãƒ¬ãƒ­ãƒ¯ãƒ²ãƒ³" {
                    return observation.topCandidates(1).first?.string
                } else {
                    return nil
                }
                
            }
//            recognizedStrings.removeAll(where: {
//                $0 == "ã‚ã„ã†ãˆãŠã‹ããã‘ã“ã•ã—ã™ã›ããŸã¡ã£ã¦ã¨ãªã«ã¬ã­ã®ã¯ã²ãµã¸ã»ã¾ã¿ã‚€ã‚ã‚‚ã‚„ã‚†ã‚ˆã‚‰ã‚Šã‚‹ã‚Œã‚ã‚ã‚’ã‚“"
//            })
            completion(recognizedStrings.first)
            print(recognizedStrings)
        }
        request.recognitionLevel = .accurate
        request.usesLanguageCorrection = false
        request.recognitionLanguages = ["ja-JP"]
        request.customWords = [
            "ã‚", "ã„", "ã†", "ãˆ", "ãŠ",
            "ã‹", "ã", "ã", "ã‘", "ã“",
            "ã•", "ã—", "ã™", "ã›", "ã",
            "ãŸ", "ã¡", "ã¤", "ã¦", "ã¨",
            "ãª", "ã«", "ã¬", "ã­", "ã®",
            "ã¯", "ã²", "ãµ", "ã¸", "ã»",
            "ã¾", "ã¿", "ã‚€", "ã‚", "ã‚‚",
            "ã‚„",      "ã‚†",       "ã‚ˆ",
            "ã‚‰", "ã‚Š", "ã‚‹", "ã‚Œ", "ã‚",
            "ã‚",                 "ã‚’",
            "ã‚“",
            
            "ã‚¢", "ã‚¤", "ã‚¦", "ã‚¨", "ã‚ª",
            "ã‚«", "ã‚­", "ã‚¯", "ã‚±", "ã‚³",
            "ã‚µ", "ã‚·", "ã‚¹", "ã‚»", "ã‚½",
            "ã‚¿", "ãƒ", "ãƒ„", "ãƒ†", "ãƒˆ",
            "ãƒŠ", "ãƒ‹", "ãƒŒ", "ãƒ", "ãƒ",
            "ãƒ", "ãƒ’", "ãƒ•", "ãƒ˜", "ãƒ›",
            "ãƒ", "ãƒŸ", "ãƒ ", "ãƒ¡", "ãƒ¢",
            "ãƒ¤",      "ãƒ¦",       "ãƒ¨",
            "ãƒ©", "ãƒª", "ãƒ«", "ãƒ¬", "ãƒ­",
            "ãƒ¯",                 "ãƒ²",
            "ãƒ³",
        ]
        
        do {
            try requestHandler.perform([request])
        } catch {
            print("OCR Error: \(error)")
        }
    }
    func extractText2(from image: UIImage, completion: @escaping (String?) -> Void) {
        guard let coreMLModel = try? HiraganaKatakanaClassifier(configuration: MLModelConfiguration()), let visionModel = try? VNCoreMLModel(for: coreMLModel.model) else {
            return completion(nil)
        }
        let request = VNCoreMLRequest(model: visionModel) { request, error in
            print(error)
            print(request)
            guard error == nil else { return completion(nil) }
            guard let classification = request.results as? [VNClassificationObservation] else { return completion(nil) }

            // ğŸ‘‰ íƒ€ì´í‹€ì„ ê°€ì¥ ì •í™•ë„ ë†’ì€ ì´ë¦„ìœ¼ë¡œ ì„¤ì •
            if let fitstItem = classification.first {
                print(classification)
                print(fitstItem)
//                completion(fitstItem.)
            }
        }

        let handler = VNImageRequestHandler(ciImage: CIImage(image: image)!)
        do {
            try handler.perform([request])
        } catch {
            print(error)
        }
    }
}
